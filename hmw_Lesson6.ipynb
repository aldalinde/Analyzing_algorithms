{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "41AitfhKbsha"
   },
   "source": [
    "# Урок 6. Градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qk-74OFhbshx"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn import model_selection\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eDZbSvqMbsh1"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "leu8bBI7bsh6"
   },
   "outputs": [],
   "source": [
    "X, y = load_diabetes(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ExZPR9FLbsh9"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7xJCdggZbsh_"
   },
   "source": [
    "Напишем функцию, реализующую предсказание в градиентном бустинге."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wU_Rkc63bsiA"
   },
   "outputs": [],
   "source": [
    "def gb_predict(X, trees_list, coef_list, eta):\n",
    "    return np.array([sum([eta*coef*alg.predict([x])[0] for alg, coef in zip(trees_list,coef_list)]) for x in X])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6gZvsyfSbsiD"
   },
   "source": [
    "В качестве функционала ошибки будем использовать среднеквадратичную ошибку. Реализуем соответствующую функицию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0xbjFIEKbsiE"
   },
   "outputs": [],
   "source": [
    "def mean_squared_error(y_real, prediction):\n",
    "    return (sum((y_real - prediction)**2)) / len(y_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WRaZEd3ebsiI"
   },
   "outputs": [],
   "source": [
    "def bias(y, z):\n",
    "    return 2*(y - z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ut-7dBgVbsiK"
   },
   "source": [
    "Реализуем функцию обучения градиентного бустинга."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HoIdAoPYbsiL"
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-9-d05e1e659071>, line 27)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-9-d05e1e659071>\"\u001b[1;36m, line \u001b[1;32m27\u001b[0m\n\u001b[1;33m    train_errors.append(mean_squared_error(y_train, gb_predict(X_train, trees, coefs, eta)))\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "def gb_fit(n_trees, max_depth, X_train, X_test, y_train, y_test, coefs, eta):\n",
    "    \n",
    "    # Деревья будем записывать в список\n",
    "    trees = []\n",
    "    \n",
    "    # Будем записывать ошибки на обучающей и тестовой выборке на каждой итерации в список\n",
    "    train_errors = []\n",
    "    test_errors = []\n",
    "    \n",
    "    for i in range(n_trees):\n",
    "        tree = DecisionTreeRegressor(max_depth=max_depth, random_state=42)\n",
    "\n",
    "        # инициализируем бустинг начальным алгоритмом, возвращающим ноль, \n",
    "        # поэтому первый алгоритм просто обучаем на выборке и добавляем в список\n",
    "        if len(trees) == 0:\n",
    "            # обучаем первое дерево на обучающей выборке\n",
    "            tree.fit(X_train, y_train)\n",
    "            \n",
    "            train_errors.append(mean_squared_error(y_train, gb_predict(X_train, trees, coefs, eta)))\n",
    "            test_errors.append(mean_squared_error(y_test, gb_predict(X_test, trees, coefs, eta)))\n",
    "        else:\n",
    "            # Получим ответы на текущей композиции\n",
    "            target = gb_predict(X_train, trees, coefs, eta)\n",
    "            \n",
    "            # алгоритмы начиная со второго обучаем на сдвиг\n",
    "            tree.fit(X_train, bias(y_train, target))\n",
    "                        train_errors.append(mean_squared_error(y_train, gb_predict(X_train, trees, coefs, eta)))\n",
    "            test_errors.append(mean_squared_error(y_test, gb_predict(X_test, trees, coefs, eta)))\n",
    "\n",
    "        trees.append(tree)\n",
    "        \n",
    "    return trees, train_errors, test_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0vkHFhhzbsiN"
   },
   "source": [
    "Теперь обучим несколько моделей с разными параметрами и исследуем их поведение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2WvxluSlbsiO"
   },
   "outputs": [],
   "source": [
    "# Число деревьев в ансамбле\n",
    "n_trees = 10\n",
    "\n",
    "# для простоты примем коэффициенты равными 1\n",
    "coefs = [1] * n_trees\n",
    "\n",
    "# Максимальная глубина деревьев\n",
    "max_depth = 3\n",
    "\n",
    "# Шаг\n",
    "eta = 1\n",
    "\n",
    "trees, train_errors, test_errors = gb_fit(n_trees, max_depth, X_train, X_test, y_train, y_test, coefs, eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GDMFn3R-bsiR"
   },
   "outputs": [],
   "source": [
    "def evaluate_alg(X_train, X_test, y_train, y_test, trees, coefs, eta):    \n",
    "    train_prediction = gb_predict(X_train, trees, coefs, eta)\n",
    "\n",
    "    print(f'Ошибка алгоритма из {n_trees} деревьев глубиной {max_depth} \\\n",
    "    с шагом {eta} на тренировочной выборке: {mean_squared_error(y_train, train_prediction)}')\n",
    "\n",
    "    test_prediction = gb_predict(X_test, trees, coefs, eta)\n",
    "\n",
    "    print(f'Ошибка алгоритма из {n_trees} деревьев глубиной {max_depth} \\\n",
    "    с шагом {eta} на тестовой выборке: {mean_squared_error(y_test, test_prediction)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WEBbjCynbsiV",
    "outputId": "e3e7bf19-aa15-4340-eceb-e2799f36140c"
   },
   "outputs": [],
   "source": [
    "evaluate_alg(X_train, X_test, y_train, y_test, trees, coefs, eta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TluGn7Iubsib"
   },
   "source": [
    "Построим графики зависимости ошибки на обучающей и тестовой выборках от числа итераций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QXrSdSgjbsic"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gjDdKkgObsif"
   },
   "outputs": [],
   "source": [
    "def get_error_plot(n_trees, train_err, test_err):\n",
    "    plt.xlabel('Iteration number')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.xlim(0, n_trees)\n",
    "    plt.plot(list(range(n_trees)), train_err, label='train error')\n",
    "    plt.plot(list(range(n_trees)), test_err, label='test error')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Was5hOJPbsih",
    "outputId": "e4a4837d-6d3e-4861-8a35-fa26d5746f62"
   },
   "outputs": [],
   "source": [
    "get_error_plot(n_trees, train_errors, test_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NS16dUwRbsik"
   },
   "source": [
    "Такой результат не является удовлетворительным"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SqfMt3KMbsis"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "eta = 0.1\n",
    "n_trees = 20\n",
    "max_depth = 10\n",
    "\n",
    "trees, train_errors, test_errors = gb_fit(n_trees, max_depth, X_train, X_test, y_train, y_test, coefs, eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Rkc97-ibsiu",
    "outputId": "c4a5a6e3-81d6-460f-ccaa-1ada3bcdb959"
   },
   "outputs": [],
   "source": [
    "evaluate_alg(X_train, X_test, y_train, y_test, trees, coefs, eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x0Ij4Fbrbsiw",
    "outputId": "9083ac69-d276-4faf-b01c-62403302c29c"
   },
   "outputs": [],
   "source": [
    "get_error_plot(n_trees, train_errors, test_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "eta = 0.1\n",
    "n_trees = 20\n",
    "max_depth = 7\n",
    "\n",
    "trees, train_errors, test_errors = gb_fit(n_trees, max_depth, X_train, X_test, y_train, y_test, coefs, eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_alg(X_train, X_test, y_train, y_test, trees, coefs, eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_error_plot(n_trees, train_errors, test_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MRpgPhisW_JM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "eta = 0.1\n",
    "n_trees = 20\n",
    "max_depth = 5\n",
    "\n",
    "trees, train_errors, test_errors = gb_fit(n_trees, max_depth, X_train, X_test, y_train, y_test, coefs, eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_alg(X_train, X_test, y_train, y_test, trees, coefs, eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_error_plot(n_trees, train_errors, test_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jtD8x98oW_Mi"
   },
   "source": [
    "### Домашнее задание:  \n",
    "1. Для реализованной модели построить графики зависимости ошибки от количества деревьев в ансамбле "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# errors depending on number of trees from 1 to 20\n",
    "errors_num_trees = []\n",
    "\n",
    "# Максимальная глубина деревьев\n",
    "max_depth = 5\n",
    "# Шаг\n",
    "eta = 0.1\n",
    "num_trees =[]\n",
    "for n in range(20):\n",
    "    coefs=[1]*n\n",
    "    trees, train_errors, test_errors = gb_fit(n+1, max_depth, X_train, X_test, y_train, y_test, coefs, eta)\n",
    "    test_pred = gb_predict(X_test, trees, coefs, eta)\n",
    "    errors_num_trees.append(mean_squared_error(y_test, test_pred))\n",
    "    num_trees.append(n+1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(num_trees, errors_num_trees)\n",
    "plt.title('Error depending on a number of the trees')\n",
    "plt.xlabel('number of the trees')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlim(0, 21)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**и от максимальной глубины деревьев. Сделать выводы о зависимости ошибки от этих параметров.**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# errors depending on max_depth from 1 to 15\n",
    "errors_max_depth = []\n",
    "# Число деревьев в ансамбле\n",
    "n_trees = 20\n",
    "# для простоты примем коэффициенты равными 1\n",
    "coefs = [1] * n_trees\n",
    "# Шаг\n",
    "eta = 0.1\n",
    "\n",
    "max_depth = []\n",
    "for mtd in range(15):\n",
    "    trees, train_errors, test_errors = gb_fit(n_trees, mtd+1, X_train, X_test, y_train, y_test, coefs, eta)\n",
    "    test_pred = gb_predict(X_test, trees, coefs, eta)\n",
    "    errors_max_depth.append(mean_squared_error(y_test, test_pred))\n",
    "    max_depth.append(mtd+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(max_depth, errors_max_depth)\n",
    "plt.title('Error depending on max depth of a tree')\n",
    "plt.xlabel('max depth of a tree')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlim(0, 16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**checking again**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "eta = 0.1\n",
    "n_trees = 20\n",
    "max_depth = 5\n",
    "\n",
    "trees, train_errors, test_errors = gb_fit(n_trees, max_depth, X_train, X_test, y_train, y_test, coefs, eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_alg(X_train, X_test, y_train, y_test, trees, coefs, eta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**\n",
    "Видимо,лучший параметр глубины дерева для данного датасета - 2. Дальше деревья слишком подстраиваются под конкретный набор данных при сплитах"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Модифицировать реализованный алгоритм, чтобы получился стохастический градиентный бустинг. Размер подвыборки принять равным 0.5. Сравнить на одном графике кривые изменения ошибки на тестовой выборке в зависимости от числа итераций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gb_predict(X, trees_list, coef_list, eta):\n",
    "    x_index = np.random.randint(X.shape[0])\n",
    "    return sum([eta*coef*alg.predict([X[x_index]])[0] for alg, coef in zip(trees_list,coef_list)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gb_fit(n_trees, max_depth, X_train, X_test, y_train, y_test, coefs, eta):\n",
    "    \n",
    "    # Деревья будем записывать в список\n",
    "    trees = []\n",
    "    \n",
    "    # Будем записывать ошибки на обучающей и тестовой выборке на каждой итерации в список\n",
    "    train_errors = []\n",
    "    test_errors = []\n",
    "    \n",
    "    for i in range(n_trees):\n",
    "        tree = DecisionTreeRegressor(max_depth=max_depth, random_state=42)\n",
    "\n",
    "        # инициализируем бустинг начальным алгоритмом, возвращающим ноль, \n",
    "        # поэтому первый алгоритм просто обучаем на выборке и добавляем в список\n",
    "        if len(trees) == 0:\n",
    "            # обучаем первое дерево на обучающей выборке\n",
    "            tree.fit(X_train, y_train)\n",
    "            \n",
    "            train_errors.append(mean_squared_error(y_train, gb_predict(X_train, trees, coefs, eta)))\n",
    "            test_errors.append(mean_squared_error(y_test, gb_predict(X_test, trees, coefs, eta)))\n",
    "        else:\n",
    "            # Получим ответы на текущей композиции\n",
    "            target = gb_predict(X_train, trees, coefs, eta)\n",
    "            \n",
    "            # алгоритмы начиная со второго обучаем на сдвиг\n",
    "            tree.fit(X_train, bias(y_train, target))\n",
    "            \n",
    "            train_errors.append(mean_squared_error(y_train, gb_predict(X_train, trees, coefs, eta)))\n",
    "            test_errors.append(mean_squared_error(y_test, gb_predict(X_test, trees, coefs, eta)))\n",
    "\n",
    "        trees.append(tree)\n",
    "        \n",
    "    return trees, train_errors, test_errors"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lesson6.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
